{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24sureshkumar/TransArt-A-Multimodal-Application-for-Vernacular-Language-Translation-and-Image-Synthesis/blob/main/TRANSART_MULTIMODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwTryaq3a7Ta",
        "outputId": "200edd0b-3b44-480d-ebcb-0c5a25e871ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok transformers diffusers accelerate sentencepiece nltk Pillow rouge_score sacrebleu --quiet\n",
        "# !pip install streamlit pyngrok transformers diffusers Pillow torch --quiet\n",
        "# !pip install bert-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "A37aQuh5eih3",
        "outputId": "e17e61f2-4bba-4e5b-9af6-0c6b5311272e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit \\\n",
        "            transformers \\\n",
        "            torch \\\n",
        "            diffusers \\\n",
        "            Pillow \\\n",
        "            rouge_score \\\n",
        "            sentencepiece \\\n",
        "            scipy \\\n",
        "            pyngrok \\\n",
        "            accelerate \\\n",
        "            nltk \\\n",
        "            sacrebleu \\\n",
        "            git+https://github.com/openai/CLIP.git --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIJ7BhLKeBKG",
        "outputId": "d060b17d-292f-4958-acce-887800e7447b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import GPT2LMHeadModel\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from rouge_score import rouge_scorer\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import os\n",
        "import time\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load translation model\n",
        "translator_model = MBartForConditionalGeneration.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ").to(device)\n",
        "translator_tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "translator_tokenizer.src_lang = \"ta_IN\"\n",
        "\n",
        "# Load GPT-2 for creative text\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device)\n",
        "gen_model.eval()\n",
        "\n",
        "# Load Stable Diffusion 2.1\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-1\",\n",
        "    use_auth_token=os.getenv(\"HF_TOKEN\"),\n",
        "    torch_dtype=torch.float32,\n",
        ").to(device)\n",
        "pipe.safety_checker = None\n",
        "\n",
        "# Load CLIP for similarity\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# --- Functions ---\n",
        "def translate_tamil_to_english(text, reference=None):\n",
        "    start = time.time()\n",
        "    inputs = translator_tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    outputs = translator_model.generate(\n",
        "        **inputs,\n",
        "        forced_bos_token_id=translator_tokenizer.lang_code_to_id[\"en_XX\"]\n",
        "    )\n",
        "    translated = translator_tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    duration = round(time.time() - start, 2)\n",
        "\n",
        "    rouge_l = None\n",
        "    if reference:\n",
        "        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        score = scorer.score(reference.lower(), translated.lower())\n",
        "        rouge_l = round(score[\"rougeL\"].fmeasure, 4)\n",
        "\n",
        "    return translated, duration, rouge_l\n",
        "\n",
        "def generate_creative_text(prompt, max_length=100):\n",
        "    start = time.time()\n",
        "    input_ids = gen_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    output = gen_model.generate(input_ids, max_length=max_length, do_sample=True, top_k=50, temperature=0.9)\n",
        "    text = gen_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    duration = round(time.time() - start, 2)\n",
        "\n",
        "    tokens = text.split()\n",
        "    repetition_rate = sum(t1 == t2 for t1, t2 in zip(tokens, tokens[1:])) / len(tokens)\n",
        "\n",
        "    # Perplexity\n",
        "    with torch.no_grad():\n",
        "        input_ids = gen_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "        outputs = gen_model(input_ids, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "        perplexity = torch.exp(loss).item()\n",
        "\n",
        "    return text, duration, len(tokens), round(repetition_rate, 4), round(perplexity, 4)\n",
        "\n",
        "def generate_image(prompt):\n",
        "    try:\n",
        "        start = time.time()\n",
        "        result = pipe(prompt)\n",
        "        image = result.images[0].resize((256, 256))\n",
        "        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n",
        "        image.save(tmp_file.name)\n",
        "        duration = round(time.time() - start, 2)\n",
        "        return tmp_file.name, duration, image\n",
        "    except Exception as e:\n",
        "        return None, 0, f\"Image generation failed: {str(e)}\"\n",
        "\n",
        "def evaluate_clip_similarity(text, image):\n",
        "    inputs = clip_processor(text=[text], images=image, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = clip_model(**inputs)\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "        probs = F.softmax(logits_per_image, dim=1)\n",
        "        similarity_score = logits_per_image[0][0].item()\n",
        "    return round(similarity_score, 4)\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "st.set_page_config(page_title=\"Tamil â†’ English + AI Art\", layout=\"centered\")\n",
        "st.title(\"ğŸ§  Tamil â†’ English + ğŸ¨ Creative Text + AI Image\")\n",
        "\n",
        "tamil_input = st.text_area(\"âœï¸ Enter Tamil text here\", height=150)\n",
        "reference_input = st.text_input(\"ğŸ“˜ Optional: Reference English translation for ROUGE\")\n",
        "\n",
        "if st.button(\"ğŸš€ Generate Output\"):\n",
        "    if not tamil_input.strip():\n",
        "        st.warning(\"Please enter Tamil text.\")\n",
        "    else:\n",
        "        with st.spinner(\"ğŸ”„ Translating Tamil to English...\"):\n",
        "            english_text, t_time, rouge_l = translate_tamil_to_english(tamil_input, reference_input)\n",
        "\n",
        "        st.success(f\"âœ… Translated in {t_time} seconds\")\n",
        "        st.markdown(f\"**ğŸ“ English Translation:** `{english_text}`\")\n",
        "        if rouge_l is not None:\n",
        "            st.markdown(f\"ğŸ“Š **ROUGE-L Score:** `{rouge_l}`\")\n",
        "        else:\n",
        "            st.info(\"â„¹ï¸ ROUGE-L not calculated. Reference not provided.\")\n",
        "\n",
        "        with st.spinner(\"ğŸ¨ Generating image...\"):\n",
        "            image_path, img_time, image_obj = generate_image(english_text)\n",
        "\n",
        "        if isinstance(image_obj, Image.Image):\n",
        "            st.success(f\"ğŸ–¼ï¸ Image generated in {img_time} seconds\")\n",
        "            st.image(Image.open(image_path), caption=\"AI-Generated Image\", use_column_width=True)\n",
        "\n",
        "            with st.spinner(\"ğŸ” Evaluating CLIP similarity...\"):\n",
        "                clip_score = evaluate_clip_similarity(english_text, image_obj)\n",
        "                st.markdown(f\"ğŸ” **CLIP Text-Image Similarity:** `{clip_score}`\")\n",
        "        else:\n",
        "            st.error(image_obj)\n",
        "\n",
        "        with st.spinner(\"ğŸ’¡ Generating creative text...\"):\n",
        "            creative, c_time, tokens, rep_rate, ppl = generate_creative_text(english_text)\n",
        "\n",
        "        st.success(f\"âœ¨ Creative text generated in {c_time} seconds\")\n",
        "        st.markdown(f\"**ğŸ§  Creative Output:** `{creative}`\")\n",
        "        st.markdown(f\"ğŸ“Œ Tokens: `{tokens}`, ğŸ” Repetition Rate: `{rep_rate}`, ğŸ“‰ Perplexity: `{ppl}`\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Built by Sureshkumar R using MBart, GPT-2, Stable Diffusion 2.1, and CLIP on Hugging Face ğŸ¤—\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9bSrUI4eA_R"
      },
      "outputs": [],
      "source": [
        "!pip install transformers diffusers accelerate streamlit pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "import os\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = \"your ngrok authtoken\"\n",
        "!ngrok config add-authtoken $NGROK_AUTHTOKEN\n",
        "\n",
        "# Run Streamlit app\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit App URL:\", public_url)\n",
        "!streamlit run app.py --server.port 8501 --server.enableCORS false"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOV9PfanexNZLjHTSVXOdiq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}